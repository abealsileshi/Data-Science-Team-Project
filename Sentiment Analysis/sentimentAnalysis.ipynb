{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "7812ea015bdcee6f23a998adcdd2ef97c151c0c241b7b7070987d9313e41299d"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /Users/kevinvo/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.ticker as tkr\n",
    "import seaborn as sns\n",
    "import scipy as stats\n",
    "\n",
    "import nltk # sentiment library\n",
    "nltk.download('vader_lexicon') # download vader lexicon\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer as SIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data/.DS_Store\ndata/stocks/Company.csv\ndata/stocks/CompanyValues.csv\ndata/tweets/Company.csv\ndata/tweets/Company_Tweet.csv\ndata/tweets/Tweet.csv\n"
     ]
    }
   ],
   "source": [
    "#provides relative paths for csv as referenced from a folder\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('data'): #path to folder\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV and import tweets\n",
    "tweets=pd.read_csv('data/tweets/Tweet.csv')\n",
    "company_tweets=pd.read_csv('data/tweets/Company_Tweet.csv')\n",
    "tweets=tweets.merge(company_tweets,how='left',on='tweet_id')\n",
    "\n",
    "# add time format dates \n",
    "tweets['date'] = pd.to_datetime(tweets['post_date'], unit='s').dt.date\n",
    "tweets.date=pd.to_datetime( tweets.date,errors='coerce')\n",
    "tweets['time'] = pd.to_datetime(tweets['post_date'], unit='s').dt.time\n",
    "#1420070457 to 2015-01-01 00:00:57"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             tweet_id ticker_symbol\n",
       "0  550803612197457920          AAPL\n",
       "1  550803610825928706          AAPL\n",
       "2  550803225113157632          AAPL\n",
       "3  550802957370159104          AAPL\n",
       "4  550802855129382912          AAPL"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>tweet_id</th>\n      <th>ticker_symbol</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>550803612197457920</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>550803610825928706</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>550803225113157632</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>550802957370159104</td>\n      <td>AAPL</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>550802855129382912</td>\n      <td>AAPL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 70
    }
   ],
   "source": [
    "len(tweets)\n",
    "len(company_tweets)\n",
    "type(tweets)\n",
    "tweets['body'][100]\n",
    "tweets['time'].head()\n",
    "company_tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tesla revenue ATH buy! all time high! =) cool\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.535, 'pos': 0.465, 'compound': 0.7256}"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "# SentimentIntensityAnalyzer is a class. \n",
    "# You need to initialize an object of SentimentIntensityAnalyzer and call the polarity_scores() method on that.\n",
    "sia = SIA()\n",
    "testSentence = \"Tesla revenue ATH buy! all time high! =) cool\"\n",
    "print(testSentence)\n",
    "sia.polarity_scores(testSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to lexicon\n",
    "pos_csv_str='buy,bull,long,support,undervalued,underpriced,cheap,upward,rising,trend,moon,rocket,hold,breakout,call,beat,support,buying,holding,high,profit,ATH,all time high, =), cool'\n",
    "neg_csv_str='sell,bear,bubble,bearish,short,overvalued,overbought,overpriced,expensive,downward,falling,sold,sell,low,put,miss,resistance,squeeze,cover,seller'\n",
    "\n",
    "dictPositive = { i : 4 for i in pos_csv_str.split(\",\") }\n",
    "dictNegative = { i : -4 for i in neg_csv_str.split(\",\") }\n",
    "add_lexicon = {**dictPositive, **dictNegative}\n",
    "# print(Financial_Lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Tesla revenue ATH buy! all time high! =) cool\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'neg': 0.0, 'neu': 0.237, 'pos': 0.763, 'compound': 0.9523}"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "source": [
    "sia.lexicon.update(add_lexicon)\n",
    "print(testSentence)\n",
    "sia.polarity_scores(testSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}